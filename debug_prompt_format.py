#!/usr/bin/env python3
"""
è°ƒè¯•æç¤ºæ ¼å¼
"""

import asyncio
import os

os.environ['CODEBUDDY_CODE_PATH'] = "/Users/jasonwang/.nvm/versions/node/v22.15.1/bin/codebuddy"
os.environ['CODEBUDDY_API_KEY'] = "ck_f9gwukdhccn4.j1twF8hHyb_wXzr8pnmeCoSYlA9OF5F8M7RBZvsLeb8"
os.environ['CODEBUDDY_INTERNET_ENVIRONMENT'] = "internal"

from app.llm import LLM
from app.schema import Message

print('ğŸ” è°ƒè¯•æç¤ºæ ¼å¼')
print('=' * 70)

async def test():
    llm = LLM(config_name="default")

    messages = [Message.user_message("è®¡ç®— 5 + 3")]
    system_msgs = [Message.system_message("ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹")]

    # æ ¼å¼åŒ–æ¶ˆæ¯
    if system_msgs:
        system_msgs_formatted = llm.format_messages(system_msgs, supports_images=False)
        messages_formatted = system_msgs_formatted + llm.format_messages(messages, supports_images=False)
    else:
        messages_formatted = llm.format_messages(messages, supports_images=False)

    print('\næ ¼å¼åŒ–åçš„æ¶ˆæ¯:')
    for i, msg in enumerate(messages_formatted):
        print(f'{i+1}. {msg}')

    # è½¬æ¢ä¸ºæç¤º
    if hasattr(llm, '_messages_to_prompt'):
        prompt = llm._messages_to_prompt(messages_formatted)
        print(f'\nè½¬æ¢åçš„æç¤º:')
        print(f'"{prompt}"')
        print(f'\næç¤ºé•¿åº¦: {len(prompt)} å­—ç¬¦')

    # æµ‹è¯•ç›´æ¥ SDK è°ƒç”¨
    print('\n' + '=' * 70)
    print('æµ‹è¯•: ç›´æ¥ SDK è°ƒç”¨ï¼ˆä½¿ç”¨è½¬æ¢åçš„æç¤ºï¼‰')
    print('=' * 70)

    from codebuddy_agent_sdk import query

    async for message in query(prompt=prompt):
        msg_type = type(message).__name__
        print(f'[{msg_type}]', end=' ')

        if msg_type == "AssistantMessage":
            if hasattr(message, 'content'):
                for block in message.content:
                    if type(block).__name__ == "TextBlock" and hasattr(block, 'text'):
                        print(block.text, end='')

        elif msg_type == "ResultMessage":
            print()
            break

asyncio.run(test())

